{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-18T15:19:40.010412500Z",
     "start_time": "2023-05-18T15:19:39.686757800Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import xml.etree.ElementTree as Xet # for parsing and creating XML data\n",
    "import pandas as pd\n",
    "import os, csv, re, nltk\n",
    "from flair.data import Corpus # in order to use the functions tha flair has\n",
    "from flair.embeddings import WordEmbeddings, StackedEmbeddings, FlairEmbeddings # these embeddings helps NER to perform better\n",
    "from itertools import islice\n",
    "from nltk.stem import WordNetLemmatizer # previously need to download \"nltk.download('wordnet')\" and \"nltk.download('omw-1.4')\". But beware if new version comes out\n",
    "from tqdm import tqdm # to display loop in a bar\n",
    "from openie import StanfordOpenIE # for using our OIE tool\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from googletrans import Translator # don't forget to run \"!pip install googletrans==3.1.0a0\" before using this"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NER (Named-Entity Recognition)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [],
   "source": [
    "# functions\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# English: en, German: de, French: fr, ... -> creates the tsv of given descriptor of any language\n",
    "def create_tsv_of_language(given_language):\n",
    "    \"\"\"\n",
    "    Before running this function below, the \"desc_\"\".xml\" file (that is downloaded from EuroVoc website) needs to be downloaded and added to package \"data/\"\"/descriptors/...\"\n",
    "    \"\"\"\n",
    "    cols = ['ID', given_language.upper()] # will be saving in a tsv with ids and their corresponding terms\n",
    "    rows = []\n",
    "\n",
    "    # parsing the xml file -> with the given EuroVoc descriptors\n",
    "    temp_path = os.getcwd()\n",
    "    temp_path = temp_path.replace(\"src\\\\main\", \"data\\\\\" + given_language + \"\\\\descriptors\\\\desc_\" + given_language + \".xml\")\n",
    "    xml_parse = Xet.parse(temp_path)\n",
    "    root = xml_parse.getroot()\n",
    "\n",
    "    # iterate through the elements of xml file\n",
    "    for element in root:\n",
    "        rows.append({\"ID\": element.find(\"DESCRIPTEUR_ID\").text, given_language.upper(): element.find(\"LIBELLE\").text})\n",
    "\n",
    "    # creating the tsv file\n",
    "    df = pd.DataFrame(rows, columns=cols)\n",
    "    df.to_csv(\"eurovoc_\" + given_language + \".tsv\", sep='\\t', index=False) # using sep='\\t' gives us a tsv file instead of csv\n",
    "\n",
    "def create_tsv_of_any_given_concept(given_concept_dict, given_language): # requires a dict in style of {EN:..., ID:...}\n",
    "    cols = ['ID', given_language.upper()] # will be saving in a tsv with ids and their corresponding terms\n",
    "    rows = []\n",
    "\n",
    "    # iterate through the elements of xml file\n",
    "    for key, value in given_concept_dict.items():\n",
    "        rows.append({\"ID\": value, given_language.upper(): key})\n",
    "\n",
    "    # creating the tsv file\n",
    "    df = pd.DataFrame(rows, columns=cols)\n",
    "    df.to_csv(\"updated_eurovoc_\" + given_language + \".tsv\", sep='\\t', index=False) # using sep='\\t' gives us a tsv file instead of csv\n",
    "\n",
    "# this function assumes we get the text annotated as [entity_value](entity_name), and assigns prefixes B, I, and 0 to each token\n",
    "def get_tokens_with_entities(raw_text: str):\n",
    "    # split the text by spaces (but not splitting the space inside the square brackets (so not splitting the \"multi-word\" entity value yet))\n",
    "    raw_tokens = re.split(r\"\\s(?![^\\[]*\\])\", raw_text)\n",
    "\n",
    "    # a regex for matching the annotation according to our notation [entity_value](entity_name)\n",
    "    entity_value_pattern = r\"\\[(?P<value>.+?)\\]\\((?P<entity>.+?)\\)\"\n",
    "\n",
    "    # flags: re.IGNORECASE and re.MULTILINE\n",
    "    entity_value_pattern_compiled = re.compile(entity_value_pattern, flags=re.I|re.M) # using it to compile a regular expression pattern provided as a string into a regex pattern object\n",
    "\n",
    "    tokens_with_entities = []\n",
    "\n",
    "    for raw_token in raw_tokens:\n",
    "        match = entity_value_pattern_compiled.match(raw_token) # if no match then returns None\n",
    "\n",
    "        if match:\n",
    "            raw_entity_name, raw_entity_value = match.group(\"entity\"), match.group(\"value\")\n",
    "\n",
    "            # we prefix the name of entity differently\n",
    "            # B- indicates beginning of an entity\n",
    "            # I- indicates the token is not a new entity itself but rather a part of existing one\n",
    "            for i, raw_entity_token in enumerate(re.split(\"\\s\", raw_entity_value)):\n",
    "                entity_prefix = \"B\" if i == 0 else \"I\"\n",
    "                entity_name = f\"{entity_prefix}-{raw_entity_name}\"\n",
    "                tokens_with_entities.append((raw_entity_token, entity_name))\n",
    "        else:\n",
    "            tokens_with_entities.append((raw_token, \"O\")) # no match\n",
    "\n",
    "    return tokens_with_entities\n",
    "\n",
    "# NLTK VERSION\n",
    "def regex_from_term_nltk(term, lemmatizer): # TODO add some kind of automatic noun-verb-... identifier for lemmatization (so parts-of-speech required to add)\n",
    "    regex = r\"\\b(\" # Regex Opening\n",
    "    tokensList = nltk.word_tokenize(term)\n",
    "\n",
    "    # Adding terms to regex\n",
    "    if len(tokensList) == 1: # in case of one-word term\n",
    "        for token in tokensList:\n",
    "            regex += token_cleaning(token, lemmatizer)\n",
    "\n",
    "    else: # if it is a multi-word term\n",
    "        decount = len(tokensList)\n",
    "        for token in tokensList:\n",
    "            decount = decount-1\n",
    "            # add between-words\n",
    "            if decount != len(tokensList)-1:\n",
    "                regex+= r'\\w*\\W\\w*\\W*'\n",
    "            # add token\n",
    "            regex += token_cleaning(token, lemmatizer)\n",
    "\n",
    "    regex += '''\\w{0,5})(\\W)''' # Regex Closure\n",
    "    return regex\n",
    "\n",
    "def token_cleaning(token, lemmatizer):\n",
    "    token = token.lower()\n",
    "    token = lemmatizer.lemmatize(token)\n",
    "    return token\n",
    "\n",
    "# Functions for document processing were taken from @https://github.com/shashankmc/eurovoc_entity_link/blob/master/EurovocTagger.py and were modified\n",
    "def tsv_dic_processing(path):\n",
    "    \"\"\"\n",
    "    :param path: the name of the eurovoc.tsv file\n",
    "    :return: Dic: Dictionary in style of {ID: Word}\n",
    "    :return: RevDic: Dictionary in style of {Word: ID}\n",
    "    :return: list1: list of IDs\n",
    "    :return: list2: list of words (concepts)\n",
    "    \"\"\"\n",
    "    # Dic, RevDic, list1, list2\n",
    "    # Only works with a 2-columns ([ID], [EN]) TSV file\n",
    "    Dic = {}\n",
    "    RevDic = {}\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    with open(path, 'rt', encoding='utf8') as csvfile:\n",
    "        myreader = csv.reader(csvfile, delimiter='\\t')\n",
    "        rcount = 0\n",
    "        for row in myreader:\n",
    "            rcount += 1\n",
    "            ccount = 0\n",
    "            if rcount > 1:\n",
    "                for cells in row:\n",
    "                    ccount += 1\n",
    "                    if ccount ==1:\n",
    "                        list1.append(cells)\n",
    "                        key = cells\n",
    "                    else:\n",
    "                        list2.append(cells)\n",
    "                        value = cells\n",
    "                Dic[key] = value\n",
    "                RevDic[value] = key\n",
    "    return Dic, RevDic, list1, list2\n",
    "\n",
    "def find_folder_with_type(given_path, doc_type): # returns all documents found in path\n",
    "    doc_list = []\n",
    "    for doc in os.listdir(given_path):\n",
    "        if re.search (r'.*\\%s$' % doc_type, doc) is not None: # even though this shows as error in IDE it's fine\n",
    "            doc_list.append(doc)\n",
    "    return doc_list\n",
    "\n",
    "\n",
    "def folder_list_to_dic(given_path, given_list):\n",
    "    dic = {}\n",
    "    old_path = os.getcwd() # saving the previous working dir so we can switch back to that dir later\n",
    "    os.chdir(given_path)\n",
    "\n",
    "    # the input should be a list of file contained in a folder\n",
    "    for file_name in given_list:\n",
    "        print('importing', file_name, '...')\n",
    "        with open(\"%s\" % file_name, \"r\", encoding='utf8') as my_file:\n",
    "            text = my_file.read()\n",
    "        dic[file_name]= text\n",
    "\n",
    "    os.chdir(old_path)\n",
    "    return dic\n",
    "\n",
    "# tagging by researching concept-regexed as a substring of the text (by using NLTK)\n",
    "def tagging_document(path_of_tagged, given_doc_list, given_doc_dic, given_concept_list, given_eurovoc_reverse_dic):\n",
    "    \"\"\"\n",
    "    This function takes the information of the descriptor (e.g., {id:concept}, id list, concept list, ...) and then with the given document information it creates the new tagged document in tagged folder. Additionally, it returns the new updated concept list which contains additional \"concepts\" found in the document text that seems to be related to one of the original concepts. Thus, expanding the vocabulary we have.\n",
    "\n",
    "    :param path_of_tagged: the location (dir) of the tagged folder\n",
    "    :param given_doc_list: a list of names of the documents\n",
    "    :param given_doc_dic: a dic that contains the contents of the document i.e. {doc_name: doc_text}\n",
    "    :param given_concept_list: the original concept list downloaded from Eurovoc\n",
    "    :param given_eurovoc_reverse_dic: opposite of \"given_concept_list\" so {concept: id}\n",
    "    :return: new_concept: this is the new expanded concept list\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    old_path = os.getcwd() # saving the previous working dir so we can switch back to that dir later\n",
    "    os.chdir(path_of_tagged)\n",
    "    new_concept_dic = given_eurovoc_reverse_dic.copy() # using the reverse eurovoc dict instead because can't add words with same id\n",
    "\n",
    "    for doc_name in given_doc_list:\n",
    "        tags_list=[]\n",
    "        tagged_text = \"\"\n",
    "        print('tagging', doc_name,'...')\n",
    "        text = given_doc_dic[doc_name]\n",
    "        text = text.lower()\n",
    "        tagged_text = text # document's initial text\n",
    "\n",
    "        # a concept tag will be done with a star (*), and the identifier with a +\n",
    "        for concept in given_concept_list:\n",
    "\n",
    "            if concept != \"\": # if concept empty, will tag everything (so need to make sure that it's not empty)\n",
    "                # REGEX CREATION: creating regex of the concept such that it can be used to search in doc later\n",
    "                regex = regex_from_term_nltk(concept, lemmatizer)\n",
    "\n",
    "                # concept = concept.strip()\n",
    "                # TAGGING #\n",
    "                # semantically neutral symbols are chosen to prevent eurovoc concepts from matching tags\n",
    "                if re.search(regex, text) is not None:\n",
    "                    # these prints can be used to check performance\n",
    "                    # print(\"Match made!\")\n",
    "                    # print(\"Found: \" + re.search(regex, text).group() + \", for concept: \" + concept)\n",
    "                    match_in_text = re.search(regex, text).group()\n",
    "                    if match_in_text not in given_concept_list:\n",
    "                        # cleaning up the matched text\n",
    "                        match_in_text = match_in_text.replace(\"\\n\", \"\")\n",
    "                        match_in_text = match_in_text.strip()\n",
    "                        match_in_text = match_in_text.strip(\".,-\")\n",
    "                        new_concept_dic[match_in_text] = given_eurovoc_reverse_dic[concept]\n",
    "\n",
    "                    tags_list.append(concept)\n",
    "                    sub_regex = r\"[\" + concept + r\"]\"\n",
    "                    sub_regex += r\"(\" + given_eurovoc_reverse_dic[concept] + r\") \" # insert the identifier\n",
    "                    tagged_text = re.sub(regex, sub_regex, tagged_text)\n",
    "\n",
    "    # create a new file with the tagged file\n",
    "        file = open(\"%s_TAGGED.txt\" % doc_name, \"w\", encoding='utf8')\n",
    "        file.write(tagged_text)\n",
    "        file.close()\n",
    "\n",
    "    os.chdir(old_path) # change back to previous path\n",
    "\n",
    "    return new_concept_dic"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T17:30:36.711768400Z",
     "start_time": "2023-05-18T17:30:36.666605500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Relations Extraction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# functions\n",
    "def get_triples_stanford_openie(given_client, given_sentence):\n",
    "    triples_list = []\n",
    "\n",
    "    # returns dict in this style: {'subject': 'Obama', 'relation': 'was born in', 'object': 'Hawaii'}\n",
    "    # for triple in tqdm(given_client.annotate(given_sentence)): # this can be used for debugging\n",
    "    for triple in given_client.annotate(given_sentence):\n",
    "        triples_list.append([triple.get(\"subject\"), triple.get(\"relation\"), triple.get(\"object\")])\n",
    "\n",
    "    return triples_list\n",
    "\n",
    "def split_text_into_sentence(given_doc_names, given_docs):\n",
    "    given_docs_tokenized = {}\n",
    "    for doc_name in given_doc_names:\n",
    "        text_of_doc = given_docs[doc_name]\n",
    "        text_of_doc = text_of_doc.replace('\\n',' ') # removing the newline string from text\n",
    "        text_of_doc = text_of_doc.replace('\\xad ','') # removing the hyphen used for line breaking\n",
    "\n",
    "        text_of_doc_tokenized = sent_tokenize(text_of_doc)\n",
    "        given_docs_tokenized[doc_name] = text_of_doc_tokenized\n",
    "\n",
    "    return given_docs_tokenized\n",
    "\n",
    "# this function is modified from \"version1_simple\" file\n",
    "def create_kg_csv(subjects, predicates, objects, re_type, model_used):\n",
    "    \"\"\"\n",
    "    [source(subject) --relation(predicate)--> target(object)]\n",
    "    :param model_used:\n",
    "    :param subjects: source\n",
    "    :param predicates: relation\n",
    "    :param objects: target\n",
    "    :param re_type: currently, we have only relation extraction type of \"simple\" and \"predefined_dictionary\"\n",
    "    :return: returns nothing only creates the csv file\n",
    "    \"\"\"\n",
    "    # field names\n",
    "    fields = ['Subject', 'Predicate', 'Object']\n",
    "    filename = os.getcwd() + \"\\\\triples_data\\\\\" + re_type + \"\\\\\" + model_used + \"\\\\kg_of_\" + re_type + \"_en.csv\"\n",
    "\n",
    "    rows = [[subjects[i], predicates[i], objects[i]] for i in range(len(subjects))]\n",
    "\n",
    "    # find out empty and None strings, replacing it with \"-\"\n",
    "    for i in range(len(rows)):\n",
    "        for j in range(len(rows[0])): # so len 3\n",
    "            if rows[i][j] == \"\" or rows[i][j] is None: rows[i][j] = \"-\"\n",
    "\n",
    "    # writing to csv file\n",
    "    with open(filename, 'w', newline = '') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow(fields) # first writing fields\n",
    "        csv_writer.writerows(rows) # now the remaining record\n",
    "\n",
    "# German: de, French: fr, but can work for any other languages too\n",
    "def simple_translator(language, re_type, model_used): # assumes that en kg csv is already created\n",
    "    translator = Translator()\n",
    "\n",
    "    filename = os.getcwd() + \"\\\\triples_data\\\\\" + re_type + \"\\\\\" + model_used\n",
    "    filename_english = filename + \"\\\\kg_of_\" + re_type + \"_en.csv\"\n",
    "    filename_assigned_language = filename + \"\\\\kg_of_\" + re_type + \"_\" + language + \".csv\"\n",
    "\n",
    "    with open(filename_english, mode =\"r\") as file_original, open(filename_assigned_language, mode = \"w\", newline = '') as file_2:\n",
    "      csv_reader = csv.reader(file_original)\n",
    "      csv_writer = csv.writer(file_2)\n",
    "\n",
    "      for lines in csv_reader: # each line is a list of 3 elements (source - relation - target)\n",
    "        source_en, relation_en, target_en = lines[0], lines[1], lines[2]\n",
    "\n",
    "        # src(source) = english, dest(destination) = language to translate to\n",
    "        translated_source, translated_relation, translated_target = translator.translate(source_en, src = \"en\", dest = language), translator.translate(relation_en, src = \"en\", dest = language), translator.translate(target_en, src = \"en\", dest = language)\n",
    "\n",
    "        temp_row = [translated_source.text, translated_relation.text, translated_target.text]\n",
    "        csv_writer.writerow(temp_row)\n",
    "\n",
    "# German: de, French: fr, but can work for any other languages too\n",
    "def simple_translator_with_concept(language, re_type, model_used, given_concept): # assumes that en kg csv is already created\n",
    "    translator = Translator()\n",
    "\n",
    "    filename = os.getcwd() + \"\\\\triples_data\\\\\" + re_type + \"\\\\\" + model_used\n",
    "    filename_english = filename + \"\\\\kg_of_\" + re_type + \"_en.csv\"\n",
    "    filename_assigned_language = filename + \"\\\\kg_of_\" + re_type + \"_\" + language + \".csv\"\n",
    "\n",
    "    with open(filename_english, mode =\"r\") as file_original, open(filename_assigned_language, mode = \"w\", newline = '') as file_2:\n",
    "      csv_reader = csv.reader(file_original)\n",
    "      csv_writer = csv.writer(file_2)\n",
    "\n",
    "      for lines in csv_reader: # each line is a list of 3 elements (source - relation - target)\n",
    "        source_en, relation_en, target_en = lines[0], lines[1], lines[2]\n",
    "\n",
    "        # src(source) = english, dest(destination) = language to translate to\n",
    "        translated_source, translated_relation, translated_target = translator.translate(source_en, src = \"en\", dest = language), translator.translate(relation_en, src = \"en\", dest = language), translator.translate(target_en, src = \"en\", dest = language)\n",
    "\n",
    "        temp_row = [translated_source.text, translated_relation.text, translated_target.text]\n",
    "        csv_writer.writerow(temp_row)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T15:21:40.241404Z",
     "start_time": "2023-05-18T15:21:40.217680200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# your own project path dir here\n",
    "my_path = \"C:\\\\Users\\\\dnaen\\\\PycharmProjects\\\\bachelor_thesis_23\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T08:41:33.909716400Z",
     "start_time": "2023-05-18T08:41:33.886762Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.Importing Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "# this has to be ran only once, because it creates the eurovoc_en.tsv file (which should already be there)\n",
    "# create_tsv_of_language(\"en\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T17:12:10.839807Z",
     "end_time": "2023-05-09T17:12:10.852387Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# to make sure that we are in the original working directory\u001B[39;00m\n\u001B[0;32m      2\u001B[0m data_path \u001B[38;5;241m=\u001B[39m my_path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124msrc\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mmain\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 3\u001B[0m \u001B[43mos\u001B[49m\u001B[38;5;241m.\u001B[39mchdir(data_path)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(os\u001B[38;5;241m.\u001B[39mgetcwd())\n",
      "\u001B[1;31mNameError\u001B[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# to make sure that we are in the original working directory\n",
    "data_path = my_path + \"\\\\src\\\\main\"\n",
    "os.chdir(data_path)\n",
    "print(os.getcwd()) # this should return something like \"...\\src\\main\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-17T10:19:03.047174600Z",
     "start_time": "2023-05-17T10:19:02.979923900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eurovoc imported\n"
     ]
    }
   ],
   "source": [
    "tsv_file = \"eurovoc_en.tsv\"\n",
    "\n",
    "# getting info of ids and concepts from the tsv file\n",
    "eurovoc_dic, eurovoc_reverse_dic, id_list, concept_list = tsv_dic_processing(tsv_file)\n",
    "print('Eurovoc imported')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T15:40:35.211003800Z",
     "start_time": "2023-05-18T15:40:35.180437800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "{'AAMS countries': '594',\n 'abandoned child': '759',\n 'abandoned land': '4444',\n 'ABM Agreement': '3509',\n 'abolition of customs duties': '4333',\n 'abortion': '4504',\n 'Abruzzi': '5075',\n 'absenteeism': '5339',\n 'absolute majority': '1746',\n 'abstentionism': '5984',\n 'abuse of power': '186',\n 'academic freedom': '3914',\n 'access to a profession': '545',\n 'access to Community information': '5399',\n 'access to education': '280',\n 'access to information': '453',\n 'access to the courts': '5400',\n 'accession criteria': '6706',\n 'accession negotiations': '6708',\n 'accession to an agreement': '5420',\n 'accession to the European Union': '12',\n 'accident in the home': '5314',\n 'accident prevention': '5810',\n 'accidental pollution': '6413',\n 'account': '61',\n 'accountant': '60',\n 'accounting': '54',\n 'accounting entry': '1333',\n 'accounting system': '4362',\n 'acculturation': '4873',\n 'acid': '5035',\n 'acid rain': '4165',\n 'acidification': '6407',\n 'acoustics': '3291',\n 'ACP countries': '5083',\n 'ACP-EC Committee of Ambassadors': '4051',\n 'ACP-EC Convention': '4049',\n 'ACP-EC Council of Ministers': '4041',\n 'ACP-EC institution': '1450',\n 'ACP-EC Joint Assembly': '5132',\n 'ACP-EC Joint Committee': '4052',\n 'acquisition of property': '5093',\n 'action brought before an administrative court': '5835',\n 'action brought before the EC Court of Justice': '5836',\n 'action by staff': '3979',\n 'action for annulment': '2940',\n 'action for annulment of an EC decision': '5837',\n 'action for failure to act': '2941',\n 'action for failure to fulfil an obligation': '2942',\n 'action programme': '2792',\n 'action to establish liability on the part of an administration': '5838',\n 'activating price': '2651',\n 'ad hoc committee': '14',\n 'adaptation of financial perspectives': '5419',\n 'added value': '4641',\n 'additional benefit': '1369',\n 'additional duty': '4329',\n 'additional resources': '3554',\n 'adhesive': '3',\n 'adjournment': '1062',\n 'adjustment to school': '6037',\n 'adjuvant': '28',\n 'administration of the Institutions': '5421',\n 'administrative autonomy': '5450',\n 'administrative code': '6610',\n 'administrative competition': '4090',\n 'administrative contract': '5536',\n 'administrative control': '171',\n 'administrative cooperation': '206',\n 'administrative court': '1539',\n 'administrative expenditure': '397',\n 'administrative formalities': '5070',\n 'administrative law': '517',\n 'administrative measure': '5217',\n 'administrative offence': '7365',\n 'administrative order': '2669',\n 'administrative penalty': '3862',\n 'administrative personnel': '3582',\n 'administrative powers': '35',\n 'administrative procedure': '2695',\n 'administrative reform': '2968',\n 'administrative responsibility': '4011',\n 'administrative science': '3923',\n 'administrative structures': '2166',\n 'administrative supervision': '5945',\n 'administrative transparency': '5936',\n 'administrative unit': '362',\n 'administrator  [V4.3]': '8542',\n 'admissibility': '2913',\n 'admission of aliens': '4005',\n 'admission to examinations': '88',\n 'ADN agreement': '3700',\n 'adopted child': '3302',\n 'adoption law': '6536',\n 'adoption of a child': '117',\n 'adoption of a law by vote': '127',\n 'adoption of the budget': '144',\n 'ADR agreement': '1195',\n 'Adriatic Sea': '5221',\n 'adult': '160',\n 'adult education': '674',\n 'advance': '4383',\n 'advance payment': '2217',\n 'advance voting': '4759',\n 'advanced materials': '3689',\n 'advanced technology industry': '1376',\n 'advertising': '2862',\n 'advertising budget': '5058',\n 'advertising malpractice': '2863',\n 'advisory power': '3046',\n 'Aegean Islands': '4171',\n 'Aegean Sea': '5223',\n 'aerated drink': '1665',\n 'aerodynamics': '4107',\n 'aeronautical industry': '1357',\n 'aerosol': '212',\n 'aerospace industry': '1358',\n 'aesthetic surgery': '6903',\n 'AETR agreement': '1283',\n 'affiliated retailing': '3212',\n 'afforestation': '5016',\n 'Afghanistan': '261',\n 'Africa': '281',\n 'African and Mauritian Common Organisation': '2102',\n \"African Charter on Human and Peoples' Rights\": '6077',\n 'African Development Bank': '4744',\n 'African organisation': '2167',\n 'African Union': '2202',\n 'after-sales service': '4104',\n 'age discrimination': '6230',\n 'age of majority': '1747',\n 'ageing of the population': '3324',\n 'agency abroad': '380',\n 'agenda': '2160',\n 'aggravating circumstances': '5489',\n 'agrarian law': '579',\n 'agrarian reform': '2970',\n 'agri-environmental plan': '6310',\n 'agri-foodstuffs': '656',\n 'agri-monetary policy': '2511',\n 'agricultural adviser': '131',\n 'agricultural advisory services': '4771',\n 'agricultural area with environmental restrictions': '6313',\n 'agricultural bank': '4752',\n 'agricultural building': '152',\n 'agricultural by-product': '4225',\n 'agricultural census': '6316',\n 'agricultural cooperative': '228',\n 'agricultural credit': '6339',\n 'agricultural disaster': '3155',\n 'agricultural economics': '638',\n 'agricultural education': '780',\n 'agricultural equipment': '846',\n 'agricultural expenditure': '5575',\n 'agricultural guidance': '2194',\n 'agricultural holding': '937',\n 'agricultural implement': '2204',\n 'agricultural insurance': '3274',\n 'agricultural labour force': '1738',\n 'agricultural land': '4445',\n 'agricultural levy': '2591',\n 'agricultural machinery': '1719',\n 'agricultural market': '1788',\n 'agricultural performance': '3605',\n 'agricultural policy': '2442',\n 'agricultural product': '2734',\n 'agricultural product nomenclature': '2068',\n 'agricultural production': '2709',\n 'agricultural production policy': '2477',\n 'agricultural productivity': '2725',\n 'agricultural quota': '2974',\n 'agricultural real estate': '2814',\n 'agricultural region': '3034',\n 'agricultural sector representative body': '7204',\n 'agricultural situation': '4117',\n 'agricultural statistics': '4257',\n 'agricultural structure': '4298',\n 'agricultural surplus': '926',\n 'agricultural trade': '613',\n 'agricultural vehicle': '4655',\n 'agricultural waste': '344',\n 'agriculture-industry relationship': '2893',\n 'agriculture-trade relationship': '2892',\n 'agro-energy': '3736',\n 'agro-industrial cropping': '323',\n 'agro-industry': '666',\n 'agroforestry': '6314',\n 'agronomic research': '2915',\n 'agronomy': '685',\n 'aid evaluation': '6374',\n 'aid for restructuring': '3069',\n 'aid in kind': '910',\n 'aid per hectare': '755',\n 'aid policy': '2460',\n 'aid programme': '2793',\n 'aid recipient': '4843',\n 'aid system': '3003',\n 'aid to agriculture': '2965',\n 'aid to disadvantaged groups': '826',\n 'aid to disaster victims': '3076',\n 'aid to industry': '3071',\n 'aid to refugees': '3075',\n 'aid to undertakings': '835',\n 'AIDS': '5172',\n 'air cabotage': '5471',\n 'air conditioning': '6012',\n 'air force': '3439',\n 'air freight rate': '4378',\n 'air law': '518',\n 'air safety': '5887',\n 'air space': '859',\n 'air traffic': '2039',\n 'air traffic control': '172',\n 'air transport': '4505',\n 'air-cushion vehicle': '4652',\n 'aircraft': '4438',\n 'aircraft carrier': '5801',\n 'aircraft fleet': '1033',\n 'airline': '3125',\n 'airport': '195',\n 'ALADI': '1094',\n 'ALADI countries': '1105',\n 'Alba  [V4.3]': '8499',\n 'Albania': '1125',\n 'alcohol': '1134',\n 'alcoholic beverage': '5018',\n 'alcoholism': '1162',\n 'Alentejo': '1177',\n 'algae': '1204',\n 'Algarve': '1187',\n 'Algeria': '1196',\n 'allergy': '5431',\n 'allocation clause': '6006',\n 'allocation of land': '222',\n 'allocation of resources': '1409',\n 'allocation of seats': '3313',\n 'allocation of work': '3321',\n 'allowances and expenses': '3557',\n 'alloy': '1340',\n 'Alpine Region': '5845',\n 'Alsace': '1430',\n 'alternate': '4328',\n 'alternative agricultural production': '2976',\n 'alternative medicine': '3289',\n 'alternative sentence': '3957',\n 'alternative service': '4106',\n 'alternative use of agricultural products': '5950',\n 'aluminium': '1446',\n 'Alytus county': '7869',\n 'amending budget': '5059',\n 'amendment': '1558',\n 'amendment of a law': '3703',\n 'America': '1587',\n 'American organisation': '2170',\n 'American Samoa': '3411',\n 'Amnesty International': '1664',\n 'amorphous materials': '3695',\n 'amortisation': '1673',\n 'analysis of causes': '6270',\n 'analytical chemistry': '5300',\n 'anarchism': '1829',\n 'anatomy': '1859',\n 'ancient history': '5661',\n 'Andalusia': '1873',\n 'Andean Community': '1190',\n 'Andean Community countries': '1191',\n 'Andean Parliament': '7205',\n 'Andorra': '1874',\n 'Anglicanism': '5162',\n 'Angola': '1876',\n 'Anguilla': '3402',\n 'anhydride': '1878',\n 'animal breeding': '3408',\n 'animal disease': '1755',\n 'animal fats': '240',\n 'animal feedingstuffs': '1224',\n 'animal health': '5877',\n 'animal leucosis': '1612',\n 'animal life': '972',\n 'animal nutrition': '1277',\n 'animal oil': '1262',\n 'animal plague': '2356',\n 'animal product': '2737',\n 'animal production': '2711',\n 'animal protein': '2845',\n 'animal resources': '3528',\n 'animal show': '5903',\n 'animal skin': '2302',\n 'animal tuberculosis': '4576',\n 'animal welfare': '5462',\n 'announcement of candidacy': '355',\n 'annual report': '2894',\n 'Antarctic Ocean': '2108',\n 'Antarctica': '1983',\n 'anthem': '4102',\n 'anti-crisis plan': '2390',\n 'anti-discriminatory measure': '3908',\n 'anti-dumping duty': '519',\n 'anti-dumping legislation': '1591',\n 'anti-dumping measure': '5332',\n 'anti-European movement': '5137',\n 'anti-missile defence': '366',\n 'anti-personnel weapon': '6377',\n 'anti-pollution device': '5593',\n 'anti-racist movement': '2000',\n 'anti-semitism': '2051',\n 'anti-subsidy proceeding': '2696',\n 'anti-trust legislation': '1592',\n 'antibiotic': '1997',\n 'antiglobalisation movement': '7373',\n 'Antigua and Barbuda': '3401',\n 'antimony': '3834',\n 'Anzus': '2070',\n 'Anzus countries': '2079',\n 'apartheid': '2086',\n 'APEC countries': '6205',\n 'aperitif': '2104',\n 'apiculture': '2115',\n 'apparatus based on the use of rays': '3874',\n 'appeal': '5954',\n 'appeal to an administrative authority': '2939',\n 'appeal to the EC Ombudsman': '5834',\n 'appeals by private individuals': '5145',\n 'application of the law': '2236',\n 'applied research': '2916',\n 'applied sciences': '3949',\n 'appointment of members  [V4.3]': '8465',\n 'appointment of staff': '3559',\n 'apprentice': '2276',\n 'apprenticeship': '2284',\n 'approval': '1252',\n 'approval of tariffs': '3103',\n 'approximation of laws': '2897',\n 'approximation of policies': '2898',\n 'Apulia': '2570',\n 'aquaculture': '2320',\n 'aquatic environment': '5741',\n 'aquatic plant': '2411',\n 'Aquitaine': '2328',\n 'Arab Common Market': '1793',\n 'Arab Common Market countries': '1794',\n 'Arab League': '1657',\n 'Arab League countries': '1658',\n 'Arab Maghreb Union  [V4.3]': '8300',\n 'Arab organisation': '2171',\n 'Arab-African cooperation': '4121',\n 'arable land': '4448',\n 'Arad  [V4.3]': '8517',\n 'Aragon': '2354',\n 'arbitrage': '2371',\n 'arbitration': '6617',\n 'arbitration clause': '6005',\n 'arboriculture': '2396',\n 'archaeology': '2453',\n 'archipelago': '5444',\n 'architectural heritage': '4100',\n 'architecture': '2471',\n 'archives': '2492',\n 'Arctic': '2503',\n 'Arctic Ocean': '2109',\n 'area management': '1157',\n 'area of freedom, security and justice': '6222',\n 'area of holding': '4337',\n 'Argentina': '2525',\n 'Arges  [V4.3]': '8521',\n 'arid zone': '4785',\n 'armed forces': '2628',\n 'Armenia': '5445',\n 'Armenian question': '3499',\n 'arms control': '3506',\n 'arms industry': '1365',\n 'arms limitation': '3455',\n 'arms policy': '3451',\n 'arms supply': '2303',\n 'arms trade': '7',\n 'aromatic plant': '2948',\n 'arrangement of working time': '1503',\n 'arrest': '3970',\n 'art education': '670',\n 'art trade': '5513',\n 'artificial food colouring': '6040',\n 'artificial insemination': '3308',\n 'artificial intelligence': '3030',\n 'artificial reproduction': '3307',\n \"artist's resale right\": '7129',\n 'artistic creation': '283',\n 'artistic profession': '3598',\n 'arts': '2688',\n 'Aruba': '2820',\n 'Arusha Convention': '196',\n 'asbestos': '1643',\n 'ASEAN': '1838',\n 'ASEAN countries': '1847',\n 'Asia': '2838',\n 'Asian and Pacific Council': '120',\n 'Asian and Pacific Development Centre': '3725',\n 'Asian Development Bank': '6336',\n 'Asian organisation': '2172',\n 'Asian Productivity Organisation': '2094',\n \"Asian-Pacific Parliamentarians' Union\": '4615',\n 'Asia–Pacific economic cooperation': '6131',\n 'assembly line production': '2708',\n 'assembly line work': '4546',\n 'assessment': '184',\n 'assessment of prices': '4397',\n 'assistance in training': '2909',\n 'assistant  [V4.3]': '8407',\n 'assisting spouse': '6717',\n 'associated action for damages': '5412',\n 'associated country': '2285',\n 'association': '2944',\n 'association agreement': '1663',\n 'Association of Caribbean States': '7415',\n 'association of local authorities': '5657',\n 'associative movement': '4153',\n 'astronautics': '6383',\n 'astronomy': '3790',\n 'asymmetric warfare  [V4.3]': '8441',\n 'atheism': '3904',\n 'Atlantic Arc': '5443',\n 'Atlantic Ocean': '2110',\n 'atlas': '3930',\n 'atmosphere': '3967',\n 'atmospheric conditions': '89',\n 'atmospheric pollutant': '2522',\n 'atmospheric pollution': '2527',\n 'atom': '5299',\n 'ATP Agreement': '5401',\n 'Attica': '7889',\n 'auction sale': '4668',\n 'audio cassette': '5477',\n 'audiovisual co-production': '5185',\n 'audiovisual communications policy': '5191',\n 'audiovisual document': '487',\n 'audiovisual equipment': '3855',\n 'audiovisual industry': '1366',\n 'audiovisual piracy': '5192',\n 'audiovisual production': '5187',\n 'audiovisual programme': '5186',\n 'audit': '6064',\n 'auditing': '4675',\n 'austerity policy': '2461',\n 'Australia': '4160',\n 'Austria': '4353',\n 'authorised catch': '5254',\n 'authoritarian regime': '3002',\n 'automatic game': '3336',\n 'automatic vending machine': '6901',\n 'automation': '4253',\n 'autonomist party': '6887',\n 'autonomous community': '5119',\n 'autonomous movement': '1999',\n 'Autonomous Province of Bolzano': '5246',\n 'Autonomous Province of Trento': '5247',\n 'autonomous territories of Palestine': '5930',\n 'autonomy': '4272',\n 'Auvergne': '4364',\n 'auxiliary worker': '3539',\n 'available energy': '2127',\n 'available energy resources': '466',\n 'average price': '2683',\n 'avian influenza  [V4.3]': '8464',\n 'aviation fuel': '3776',\n 'award of contract': '20',\n 'axle tax': '4398',\n 'axle weight': '5388',\n 'Azerbaijan': '5454',\n 'Azores': '5076',\n 'baby food': '1240',\n 'Bacau  [V4.3]': '8506',\n 'backlog of court cases': '6618',\n 'backwardness at school': '3615',\n 'bad weather': '5683',\n 'Baden-Württemberg': '4560',\n 'Bahamas': '4567',\n 'Bahrain': '4572',\n 'bailiff': '1272',\n 'bakery': '5031',\n 'balance of payments': '4671',\n 'balance sheet': '4884',\n 'balance-of-payments deficit': '4644',\n 'balance-sheet analysis': '1782',\n 'Balearic Islands': '3386',\n 'Bali': '4679',\n 'ballistic missile': '3425',\n 'ballot paper': '5064',\n 'Baltic Sea': '1871',\n 'Baltic States': '5774',\n 'Bangladesh': '4732',\n 'bank': '4738',\n 'bank charges': '3252',\n 'bank deposit': '408',\n 'Bank for International Settlements': '5044',\n 'banking': '2149',\n 'banking policy': '2447',\n 'banking profession': '3612',\n 'banking secrecy': '3994',\n 'banking supervision': '3251',\n 'banking system': '4356',\n 'bankruptcy': '960',\n 'Banská Bystrica region': '7837',\n 'bar': '4819',\n 'Barbados': '4816',\n 'barge': '2316',\n 'barge carrier ship': '2044',\n 'barley': '2193',\n 'barring of penalties by limitation': '2597',\n 'barrister': '5141',\n 'barter': '4573',\n 'basic education': '672',\n 'basic needs': '6781',\n 'basic price': '2650',\n 'basic research': '3670',\n 'Basilicata': '4823',\n 'basis of tax assessment': '2900',\n 'basket of currencies': '2225',\n 'Basque Country': '2289',\n 'bathing water': '600',\n 'bauxite': '3755',\n 'Bavaria': '4835',\n 'bear  [V4.3]': '8445',\n 'bearing': '3759',\n 'beef': '4682',\n 'beef animal': '5012',\n 'beer': '4883',\n 'beet sugar': '4317',\n 'behavioural sciences': '3928',\n 'Belarus': '5458',\n 'Belgian communities': '5517',\n 'Belgium': '4839',\n 'Belgo-Luxembourg Economic Union': '4588',\n 'Belize': '4841',\n 'benchmarking': '6362',\n 'Benelux': '4844',\n 'Benelux countries': '4845',\n 'Benin': '4846',\n 'Berlin': '4847',\n 'Bermuda': '4848',\n 'beryllium': '3835',\n 'BEUC': '4859',\n 'beverage': '5017',\n 'beverage industry': '1378',\n 'Bhutan': '4862',\n 'bibliography': '4864',\n 'bicameral system': '4871',\n 'Bihor  [V4.3]': '8511',\n 'bilateral agreement': '3462',\n 'bilateral aid': '845',\n 'bilateral relations': '3196',\n 'bilingualism': '4888',\n 'bio-ethics': '5169',\n 'bio-industry': '3796',\n 'biochemistry': '4889',\n 'bioclimatology': '6385',\n 'bioconversion': '4890',\n 'biodegradability': '4891',\n 'biodiversity': '5463',\n 'bioenergy': '4892',\n 'biofuel  [V4.3]': '8412',\n 'biogas': '4900',\n 'biography': '4905',\n 'biological standard': '2080',\n 'biological weapon': '3419',\n 'biology': '4921',\n 'biomass': '4930',\n 'biomaterials': '3697',\n 'biometrics': '7410',\n 'bioprocess': '3795',\n 'biosphere': '4940',\n 'biotechnology': '3797',\n 'biotope': '5464',\n 'bipolarisation': '4959',\n 'bird': '5760',\n 'birth control': '3168',\n 'birth policy': '2480',\n 'births': '2029',\n 'biscuit factory': '4984',\n 'bismuth': '4990',\n 'Bistrita-Nasaud  [V4.3]': '8512',\n 'bituminous materials': '3756',\n 'Black Sea': '5736',\n 'Blagoevgrad region  [V4.3]': '8333',\n 'blank ballot paper': '4751',\n 'Blekinge county': '7998',\n 'blog  [V4.3]': '8413',\n 'blood disease': '5717',\n 'blood transfusion': '5293',\n 'blue-collar worker': '2207',\n 'blue-veined cheese': '1107',\n 'board of directors': '115',\n 'boarding school': '5687',\n 'boiler': '5397',\n 'Bolivia': '5020',\n 'bolt and screw industry': '3825',\n 'bomber': '5468',\n 'Bonaire': '5022',\n 'bond': '2098',\n 'bonded wood': '3884',\n 'boned meat': '4688',\n 'bonus payment': '2619',\n 'book trade': '1392',\n 'bookshop': '1629',\n 'border control': '5540',\n 'border war': '1213',\n 'boreal forest': '6323',\n 'Borneo': '5026',\n 'borrowing': '736',\n 'Bosnia and Herzegovina': '5469',\n 'botany': '5028',\n 'Botosani  [V4.3]': '8505',\n 'Botswana': '5029',\n 'bottled wine': '4719',\n 'bottling': '722',\n 'bracket price': '2633',\n 'bracket rate': '3266',\n 'Braila  [V4.3]': '8528',\n 'brain drain': '934',\n 'branch': '4313',\n 'branch of activity': '5985',\n 'brand name': '3661',\n 'Brandenburg': '5470',\n 'Brasov  [V4.3]': '8500',\n 'Bratislava region': '7830',\n 'Brazil': '5040',\n 'breach of domicile': '1498',\n 'breach of trust': '2',\n 'bread': '2221',\n 'bread-making': '2226',\n 'breadwinner': '4234',\n 'breeder reactor': '4341',\n 'breeding animal': '1929',\n 'Bremen': '5039',\n 'Bretton Woods Agreement': '1858',\n 'brick': '6821',\n 'bridge  [V4.3]': '8452',\n 'British Antarctic Territory  [V4.3]': '8371',\n 'British Indian Ocean Territory  [V4.3]': '8373',\n 'British Virgin Islands': '1299',\n 'British West Indies': '2024',\n 'Brittany': '5041',\n 'broadcast videography': '4698',\n 'broadcasting': '2883',\n 'broker': '263',\n 'bromine': '5046',\n 'browser': '6182',\n 'brucellosis': '5047',\n 'Brunei': '5049',\n 'Brussels region': '3039',\n 'BSE bovine spongiform encephalopathy': '6112',\n 'Bucharest — Ilfov  [V4.3]': '8490',\n 'buckwheat': '3898',\n 'Buddhism': '5030',\n 'Buddhist': '7339',\n 'Buddhist law': '6730',\n 'budget': '5050',\n 'budget appropriation': '3253',\n 'budget authorisation': '4301',\n 'budget deficit': '368',\n 'budget estimate': '2615',\n 'budget financing': '1012',\n 'budget policy': '2448',\n 'budget volume': '1824',\n 'budgetary amendment': '1959',\n 'budgetary assessment': '917',\n 'budgetary classification': '2067',\n 'budgetary control': '173',\n 'budgetary cooperation': '6028',\n 'budgetary discharge': '341',\n 'budgetary equilibrium': '843',\n 'budgetary expenditure': '394',\n 'budgetary power': '2574',\n 'budgetary procedure': '2698',\n 'budgetary resources': '3558',\n 'budgetary specification': '4241',\n 'budgetary stabiliser': '5904',\n 'buffalo meat': '4685',\n 'buffer stock': '4290',\n 'building': '4831',\n 'building industry': '3879',\n 'building insulation': '1514',\n 'building materials': '1826',\n 'building permit': '2327',\n 'building plot': '4442',\n 'building regulations': '3134',\n 'building safety': '5309',\n 'building services': '4414',\n 'building slab': '3881',\n 'building speculation': '4243',\n 'building subsidy': '775',\n 'building technique': '6916',\n 'built-up area': '490',\n 'bulb vegetable': '1603',\n 'Bulgaria': '5063',\n 'bulk product': '2756',\n 'bull': '4388',\n 'bureau of parliament': '5068',\n 'Bureau of the EP': '4174',\n 'Burgas region  [V4.3]': '8329',\n 'Burgenland': '6196',\n 'Burgundy': '5032',\n 'Burkina Faso': '1236',\n 'Burundi': '5072',\n 'bus': '4197',\n 'bus station': '7359',\n 'business activity': '4703',\n 'business administration': '644',\n 'business data processing': '1427',\n 'business lease': '4606',\n 'business location': '1307',\n 'business management': '1156',\n 'business morals': '7201',\n 'business name': '2889',\n 'business park  [V4.3]': '8450',\n 'business policy': '2469',\n 'business start-up': '5205',\n 'business tax': '4406',\n 'BusinessEurope': '6148',\n 'butane': '3768',\n 'butter': '4860',\n 'butter oil': '5073',\n 'buying group': '1199',\n 'Buzau  [V4.3]': '8529',\n 'by-catch': '5253',\n 'by-election': '702',\n 'by-product': '4224',\n 'cabinet reshuffle': '3260',\n 'cable distribution': '4428',\n 'cable transport': '4527',\n 'CACM countries': '1844',\n 'cadmium': '3836',\n 'CAEMC countries': '4587',\n 'CAEU countries  [V4.3]': '8369',\n 'CAIS countries': '2117',\n 'Calabria': '5091',\n 'Calarasi  [V4.3]': '8522',\n 'calcium': '5304',\n 'calf': '4650',\n 'Cambodia': '1555',\n 'Cameroon': '5095',\n 'Campania': '5098',\n 'camping': '5099',\n 'camping vehicle': '5331',\n 'Canada': '5100',\n 'Canary Islands': '4172',\n 'cancer': '5104',\n 'candidate': '5105',\n 'cane sugar': '4319',\n 'cannery': '136',\n 'canon law': '6731',\n 'Cantabria': '3385',\n 'capacity to contract': '5112',\n 'capacity to exercise rights': '5110',\n 'capacity to have rights and obligations': '5113',\n 'Cape Verde': '5108',\n 'capital city': '5230',\n 'capital depreciation': '409',\n 'capital gains tax': '1323',\n 'capital goods': '3197',\n 'capital increase': '4115',\n 'capital market': '5156',\n 'capital movement': '2002',\n 'capital transfer': '4493',\n 'capital transfer tax': '1324',\n 'Caras-Severin  [V4.3]': '8518',\n 'carbon': '5261',\n 'carcase': '5263',\n 'carcinogenic substance': '4307',\n 'cardiovascular disease': '1757',\n 'care allowance': '7946',\n 'care for the elderly': '6233',\n 'care of mothers and infants': '2843',\n 'care of the disabled': '4209',\n 'cargo vessel': '2043',\n 'Caribbean Development Bank': '6338',\n 'Caribbean Islands': '5259',\n 'Caricom': '5264',\n 'Caricom countries': '5265',\n 'Carinthia': '6197',\n 'Caroline Islands': '1292',\n 'carpet': '4377',\n 'carriage for hire or reward': '4529',\n 'carriage of goods': '4509',\n 'carriage of passengers': '4511',\n 'carrier': '4542',\n 'carry-over of appropriations': '3350',\n 'carrying capacity': '5111',\n 'carrying out of sentence': '5631',\n 'cartel': '5267',\n 'cartography': '5269',\n 'case study': '5628',\n 'case-law': '1550',\n 'cash flow': '5270',\n 'Caspian Sea': '5735',\n 'cassava': '1781',\n 'cast-iron': '1059',\n 'Castile-La Mancha': '3384',\n 'Castile-Leon': '3382',\n 'castor bean': '3724',\n 'casual employment': '6718',\n 'catalogue': '5274',\n 'cataloguing': '5272',\n 'Catalonia': '5273',\n 'catch area': '4788',\n 'catch by species': '5256',\n 'catch of fish': '5255',\n 'catch quota': '2879',\n 'catering': '3563',\n 'catering industry': '1373',\n 'catering profession': '5167',\n 'Catholicism': '5163',\n 'cattle': '5034',\n 'Caucasus countries': '7208',\n 'Cayman Islands': '1291',\n 'CCT duties': '4080',\n 'cease-fire': '5375',\n 'Cedefop': '5342',\n 'CEFTA': '7185',\n 'CEFTA countries  [V4.3]': '8278',\n 'cellulose': '5346',\n 'cement': '5993',\n 'cemetery': '5488',\n 'Cenelec': '6094',\n 'censorship': '5348',\n 'census': '2907',\n 'Central Africa': '302',\n 'Central African Economic and Monetary Community': '4586',\n 'Central African Republic': '5349',\n 'Central America': '1606',\n 'Central American Bank for Economic Integration': '6337',\n 'Central American Common Market': '3727',\n 'Central American Integration System': '2116',\n 'Central American Parliament': '7206',\n 'Central and Eastern European Countries': '5781',\n 'Central Asia': '5448',\n 'central bank': '4763',\n 'Central Bohemia': '7853',\n 'Central Commission for Navigation on the Rhine': '7186',\n 'Central Estonia': '7858',\n 'central government': '38',\n 'Central Greece': '1183',\n 'Central Hungary': '7901',\n 'Central Macedonia': '7891',\n 'Central Portugal': '3394',\n 'central rate': '4394',\n 'Central Slovenia': '7829',\n 'Central Transdanubia': '7903',\n 'centralisation of information': '5351',\n 'Centre (France)': '5352',\n 'Centre for the Development of Enterprise': '5282',\n 'Centru (Romania)  [V4.3]': '8491',\n 'CEPT': '5248',\n 'ceramics': '5359',\n 'cereal flakes': '1029',\n 'cereal flour': '970',\n 'cereal product': '2729',\n 'cereal substitute': '2990',\n 'cereal-growing': '318',\n 'cereals': '5360',\n 'cereals of bread-making quality': '5364',\n 'CERN': '5365',\n 'certificate of origin': '5367',\n 'cervidae': '6918',\n 'cessation of farming': '5373',\n 'cessation of trading': '5372',\n 'Ceuta': '6282',\n 'Ceuta and Melilla': '3388',\n 'CFSP': '5788',\n 'Chad': '4410',\n 'chain store': '3215',\n 'challenge  [V4.3]': '8458',\n 'chamber of commerce and industry': '5376',\n 'champagne': '5380',\n 'Champagne-Ardenne': '5381',\n 'change of job': '3523',\n 'change of political system': '5483',\n 'Channel Islands': '1290',\n 'chaptalisation': '5385',\n 'charcoal': '5244',\n 'charge': '4882',\n 'charge having equivalent effect': '4403',\n 'charges for use of infrastructure': '4387',\n 'charter on human rights': '3902',\n 'chartering': '254',\n 'Chechen question  [V4.3]': '8355',\n 'cheese': '1102',\n 'cheese factory': '1113',\n 'chemical accident': '6914',\n 'chemical alcohol': '1143',\n 'chemical compound': '3810',\n 'chemical element': '3809',\n 'chemical fertiliser': '765',\n 'chemical industry': '1362',\n 'chemical pollution': '2528',\n 'chemical process': '2692',\n 'chemical product': '2739',\n 'chemical salt': '4062',\n 'chemical waste': '6410',\n 'chemical weapon': '2557',\n 'chemistry': '5966',\n 'cheque': '5963',\n 'child': '758',\n 'child care': '1133',\n 'child labour': '4552',\n 'child of migrant': '760',\n 'child pornography': '6553',\n 'child protection': '3919',\n \"children's library\": '4866',\n \"children's rights\": '3916',\n 'Chile': '5965',\n 'China': '5969',\n 'chlorine': '5971',\n 'choice of technology': '5973',\n 'Christian': '6545',\n 'Christian Democratic Party': '2253',\n 'Christianity': '5987',\n 'chromium': '5988',\n 'chronic illness': '6567',\n 'church': '4101',\n 'church-State relations': '3221',\n 'cider': '5990',\n 'cif price': '2641',\n 'cindynics': '6715',\n 'cinema': '5994',\n 'circular': '5995',\n 'CIS countries': '5775',\n \"citizen's duties\": '7347',\n 'citizen-authority relations': '5852',\n \"citizens' Europe\": '5629',\n 'citrus fruit': '693',\n 'CIV Convention': '193',\n 'civics': '3276',\n 'civil aviation': '4408',\n 'civil bankruptcy  [V4.3]': '8432',\n 'civil code': '5496',\n 'civil defence': '3057',\n 'civil disobedience': '419',\n 'civil engineering': '1145',\n 'civil law': '523',\n 'civil liability': '3926',\n 'civil liability proceedings': '5416',\n 'civil procedure': '2699',\n 'civil proceedings': '5414',\n 'civil register': '5850',\n 'civil rights': '583',\n 'civil servant': '1047',\n 'civil servants’ union': '3573',\n 'civil service': '1046',\n 'civil society  [V4.3]': '8428',\n 'civil status': '884',\n 'civil union': '7414',\n 'civil war': '1211',\n 'civilian personnel': '5783',\n 'civilian victim': '4696',\n 'civilisation': '5996',\n 'claim': '5559',\n 'clandestine worker': '4556',\n 'class struggle': '1710',\n 'classification': '6004',\n 'classified forest': '1064',\n 'clean technology': '3638',\n 'cleaning industry': '5466',\n 'clearing agreement': '1918',\n 'clearing of land': '370',\n 'clergy': '6009',\n 'climate': '6011',\n 'climate change': '5482',\n 'climatic zone': '4786',\n 'climatology': '6384',\n 'clock and watch industry': '1403',\n 'cloning': '6171',\n 'closing of accounts': '6013',\n 'clothing': '4680',\n 'clothing industry': '1397',\n 'clover': '4566',\n 'Cluj  [V4.3]': '8513',\n 'co-determination': '6026',\n 'co-financing': '6025',\n 'co-insurance': '3244',\n 'coal': '5386',\n 'coal by-products industry': '5260',\n 'coal industry': '3743',\n 'coal mining': '5387',\n 'coal processing': '3746',\n 'coalmining policy': '3745',\n 'coastal pollution': '2532',\n 'coastal protection': '3142',\n 'coastal region': '3043',\n 'cobalt': '6018',\n 'cocoa': '5078',\n 'code of conduct': '3482',\n 'codecision procedure': '5815',\n 'codification of Community law': '5498',\n 'coding': '6019',\n 'coffee': '5088',\n 'cohabitation': '74',\n 'Cohesion Fund': '5643',\n 'coke': '6027',\n 'cold store': '3846',\n 'cold war': '1214',\n 'collective activities': '4702',\n ...}"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eurovoc_reverse_dic"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T15:48:07.942339300Z",
     "start_time": "2023-05-18T15:48:07.908039700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Directive_(EU)_2016_1919_en.txt ...\n",
      "importing Directive_(EU)_2016_343_en.txt ...\n",
      "importing Directive_(EU)_2016_800_en.txt ...\n",
      "importing Directive_2010_64_EU_en.txt ...\n",
      "importing Directive_2012_13_EU_en.txt ...\n",
      "importing Directive_2013_48_EU_en.txt ...\n"
     ]
    }
   ],
   "source": [
    "# Extracting all existing txt documents in the path\n",
    "data_path = my_path + \"\\\\data\\\\en\\\\directives_txt\"\n",
    "document_name_list = find_folder_with_type(data_path, '.txt') # detection of txt files in the folder\n",
    "document_dic = folder_list_to_dic(data_path, document_name_list) # storing document content in a dictionary"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T16:34:25.035698900Z",
     "start_time": "2023-05-18T16:34:25.008810200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Entity Extraction (NER)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tagging Directive_(EU)_2016_1919_en.txt ...\n",
      "tagging Directive_(EU)_2016_343_en.txt ...\n",
      "tagging Directive_(EU)_2016_800_en.txt ...\n",
      "tagging Directive_2010_64_EU_en.txt ...\n",
      "tagging Directive_2012_13_EU_en.txt ...\n",
      "tagging Directive_2013_48_EU_en.txt ...\n"
     ]
    }
   ],
   "source": [
    "# tagging document\n",
    "os.chdir(my_path + \"\\\\src\\\\main\")\n",
    "print(os.getcwd())\n",
    "data_path = my_path + \"\\\\data\\\\en\\\\directives_txt_tagged\"\n",
    "updated_concept_list = tagging_document(data_path, document_name_list, document_dic, concept_list, eurovoc_reverse_dic)\n",
    "print(os.getcwd())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T17:26:38.144171700Z",
     "start_time": "2023-05-18T17:25:49.273888Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "# have to run this only once (if file \"updated_eurovoc_en.tsv\" exists no need to run it)\n",
    "create_tsv_of_any_given_concept(updated_concept_list, \"en\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T17:27:37.717216800Z",
     "start_time": "2023-05-18T17:27:37.676360500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Relation Extraction (RE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# !pip install stanford_openie"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# https://stanfordnlp.github.io/CoreNLP/openie.html#api\n",
    "# Default value of openie.affinity_probability_cap was 1/3.\n",
    "properties = {\n",
    "    'openie.affinity_probability_cap': 2 / 3,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T08:40:32.855242900Z",
     "start_time": "2023-05-18T08:40:32.814395800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting server with command: java -Xmx8G -cp C:\\Users\\dnaen\\.stanfordnlp_resources\\stanford-corenlp-4.5.3/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-7e1f36d3683141db.props -preload openie\n",
      "Document Directive_2013_48_EU_en.txtfinished\n"
     ]
    }
   ],
   "source": [
    "document_dic_tokenized = split_text_into_sentence(document_name_list, document_dic)\n",
    "list_of_triples = []\n",
    "with StanfordOpenIE(properties=properties) as client: # opening the server\n",
    "    for doc_name in document_name_list:\n",
    "        for sentence in document_dic_tokenized[doc_name]:\n",
    "            current_triple_list_of_sentence = get_triples_stanford_openie(client, sentence) # returns [subject, relation, object]\n",
    "            if current_triple_list_of_sentence: # only run the loop if list not empty\n",
    "                for current_triple in current_triple_list_of_sentence: # a sentence can have multiple triples\n",
    "                    list_of_triples.append(current_triple)\n",
    "        print(\"Document \" + doc_name + \"finished\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T10:18:49.129130500Z",
     "start_time": "2023-05-18T10:17:14.214951600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# extract subject\n",
    "source = [i[0] for i in list_of_triples]\n",
    "\n",
    "# extract relation\n",
    "relation = [i[1] for i in list_of_triples]\n",
    "\n",
    "# extract object\n",
    "target = [i[2] for i in list_of_triples]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T10:22:41.304542100Z",
     "start_time": "2023-05-18T10:22:41.280708Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4. Build Knowledge Graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FALSE: C:\\Users\\dnaen\\PycharmProjects\\bachelor_thesis_23\\src\\main\\triples_data\\predefined_dictionary\\stanford_OpenIE\\kg_of_predefined_dictionary_en.csv\n",
      "CORRET: C:\\Users\\dnaen\\PycharmProjects\\bachelor_thesis_23\\src\\main\\triples_data\\predefined_dictionary\\stanford_OpenIE\\kg_of_predefined-dictionary_en.csv\n"
     ]
    }
   ],
   "source": [
    "data_path = my_path + \"\\\\src\\\\main\"\n",
    "os.chdir(data_path)\n",
    "\n",
    "create_kg_csv(source, relation, target, \"predefined_dictionary\", \"stanford_OpenIE\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T10:38:21.401315700Z",
     "start_time": "2023-05-18T10:38:21.332934600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5. Translate\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "ename": "ConnectTimeout",
     "evalue": "timed out",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mConnectTimeout\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[73], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43msimple_translator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mde\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpredefined_dictionary\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstanford_OpenIE\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[69], line 68\u001B[0m, in \u001B[0;36msimple_translator\u001B[1;34m(language, re_type, model_used)\u001B[0m\n\u001B[0;32m     65\u001B[0m source_en, relation_en, target_en \u001B[38;5;241m=\u001B[39m lines[\u001B[38;5;241m0\u001B[39m], lines[\u001B[38;5;241m1\u001B[39m], lines[\u001B[38;5;241m2\u001B[39m]\n\u001B[0;32m     67\u001B[0m \u001B[38;5;66;03m# src(source) = english, dest(destination) = language to translate to\u001B[39;00m\n\u001B[1;32m---> 68\u001B[0m translated_source, translated_relation, translated_target \u001B[38;5;241m=\u001B[39m translator\u001B[38;5;241m.\u001B[39mtranslate(source_en, src \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124men\u001B[39m\u001B[38;5;124m\"\u001B[39m, dest \u001B[38;5;241m=\u001B[39m language), \u001B[43mtranslator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranslate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrelation_en\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43men\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mlanguage\u001B[49m\u001B[43m)\u001B[49m, translator\u001B[38;5;241m.\u001B[39mtranslate(target_en, src \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124men\u001B[39m\u001B[38;5;124m\"\u001B[39m, dest \u001B[38;5;241m=\u001B[39m language)\n\u001B[0;32m     70\u001B[0m temp_row \u001B[38;5;241m=\u001B[39m [translated_source\u001B[38;5;241m.\u001B[39mtext, translated_relation\u001B[38;5;241m.\u001B[39mtext, translated_target\u001B[38;5;241m.\u001B[39mtext]\n\u001B[0;32m     71\u001B[0m csv_writer\u001B[38;5;241m.\u001B[39mwriterow(temp_row)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\googletrans\\client.py:210\u001B[0m, in \u001B[0;36mTranslator.translate\u001B[1;34m(self, text, dest, src, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[0;32m    209\u001B[0m origin \u001B[38;5;241m=\u001B[39m text\n\u001B[1;32m--> 210\u001B[0m data, response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_translate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    212\u001B[0m \u001B[38;5;66;03m# this code will be updated when the format is changed.\u001B[39;00m\n\u001B[0;32m    213\u001B[0m translated \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([d[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m d[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m data[\u001B[38;5;241m0\u001B[39m]])\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\googletrans\\client.py:108\u001B[0m, in \u001B[0;36mTranslator._translate\u001B[1;34m(self, text, dest, src, override)\u001B[0m\n\u001B[0;32m    104\u001B[0m params \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mbuild_params(client\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient_type, query\u001B[38;5;241m=\u001B[39mtext, src\u001B[38;5;241m=\u001B[39msrc, dest\u001B[38;5;241m=\u001B[39mdest,\n\u001B[0;32m    105\u001B[0m                             token\u001B[38;5;241m=\u001B[39mtoken, override\u001B[38;5;241m=\u001B[39moverride)\n\u001B[0;32m    107\u001B[0m url \u001B[38;5;241m=\u001B[39m urls\u001B[38;5;241m.\u001B[39mTRANSLATE\u001B[38;5;241m.\u001B[39mformat(host\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pick_service_url())\n\u001B[1;32m--> 108\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m r\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m200\u001B[39m:\n\u001B[0;32m    111\u001B[0m     data \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mformat_json(r\u001B[38;5;241m.\u001B[39mtext)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\httpx\\_client.py:755\u001B[0m, in \u001B[0;36mClient.get\u001B[1;34m(self, url, params, headers, cookies, auth, allow_redirects, timeout)\u001B[0m\n\u001B[0;32m    744\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\n\u001B[0;32m    745\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    746\u001B[0m     url: URLTypes,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    753\u001B[0m     timeout: typing\u001B[38;5;241m.\u001B[39mUnion[TimeoutTypes, UnsetType] \u001B[38;5;241m=\u001B[39m UNSET,\n\u001B[0;32m    754\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Response:\n\u001B[1;32m--> 755\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    756\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mGET\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    757\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    758\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    759\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    760\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcookies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcookies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    761\u001B[0m \u001B[43m        \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    762\u001B[0m \u001B[43m        \u001B[49m\u001B[43mallow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    763\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    764\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\httpx\\_client.py:600\u001B[0m, in \u001B[0;36mClient.request\u001B[1;34m(self, method, url, data, files, json, params, headers, cookies, auth, allow_redirects, timeout)\u001B[0m\n\u001B[0;32m    575\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[0;32m    576\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    577\u001B[0m     method: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    588\u001B[0m     timeout: typing\u001B[38;5;241m.\u001B[39mUnion[TimeoutTypes, UnsetType] \u001B[38;5;241m=\u001B[39m UNSET,\n\u001B[0;32m    589\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Response:\n\u001B[0;32m    590\u001B[0m     request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuild_request(\n\u001B[0;32m    591\u001B[0m         method\u001B[38;5;241m=\u001B[39mmethod,\n\u001B[0;32m    592\u001B[0m         url\u001B[38;5;241m=\u001B[39murl,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    598\u001B[0m         cookies\u001B[38;5;241m=\u001B[39mcookies,\n\u001B[0;32m    599\u001B[0m     )\n\u001B[1;32m--> 600\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    601\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_redirects\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    602\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\httpx\\_client.py:620\u001B[0m, in \u001B[0;36mClient.send\u001B[1;34m(self, request, stream, auth, allow_redirects, timeout)\u001B[0m\n\u001B[0;32m    616\u001B[0m timeout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(timeout, UnsetType) \u001B[38;5;28;01melse\u001B[39;00m Timeout(timeout)\n\u001B[0;32m    618\u001B[0m auth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuild_auth(request, auth)\n\u001B[1;32m--> 620\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_handling_redirects\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    621\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    622\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    624\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n\u001B[0;32m    625\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\httpx\\_client.py:647\u001B[0m, in \u001B[0;36mClient.send_handling_redirects\u001B[1;34m(self, request, auth, timeout, allow_redirects, history)\u001B[0m\n\u001B[0;32m    644\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(history) \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_redirects:\n\u001B[0;32m    645\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m TooManyRedirects()\n\u001B[1;32m--> 647\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_handling_auth\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    648\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhistory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhistory\u001B[49m\n\u001B[0;32m    649\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    650\u001B[0m response\u001B[38;5;241m.\u001B[39mhistory \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(history)\n\u001B[0;32m    652\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m response\u001B[38;5;241m.\u001B[39mis_redirect:\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\httpx\\_client.py:684\u001B[0m, in \u001B[0;36mClient.send_handling_auth\u001B[1;34m(self, request, history, auth, timeout)\u001B[0m\n\u001B[0;32m    682\u001B[0m request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(auth_flow)\n\u001B[0;32m    683\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 684\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_single_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    685\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m auth\u001B[38;5;241m.\u001B[39mrequires_response_body:\n\u001B[0;32m    686\u001B[0m         response\u001B[38;5;241m.\u001B[39mread()\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\httpx\\_client.py:714\u001B[0m, in \u001B[0;36mClient.send_single_request\u001B[1;34m(self, request, timeout)\u001B[0m\n\u001B[0;32m    705\u001B[0m transport \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransport_for_url(request\u001B[38;5;241m.\u001B[39murl)\n\u001B[0;32m    707\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    708\u001B[0m     (\n\u001B[0;32m    709\u001B[0m         http_version,\n\u001B[0;32m    710\u001B[0m         status_code,\n\u001B[0;32m    711\u001B[0m         reason_phrase,\n\u001B[0;32m    712\u001B[0m         headers,\n\u001B[0;32m    713\u001B[0m         stream,\n\u001B[1;32m--> 714\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[43mtransport\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    715\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    716\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    717\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    718\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    719\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    720\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    721\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m HTTPError \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m    722\u001B[0m     \u001B[38;5;66;03m# Add the original request to any HTTPError unless\u001B[39;00m\n\u001B[0;32m    723\u001B[0m     \u001B[38;5;66;03m# there'a already a request attached in the case of\u001B[39;00m\n\u001B[0;32m    724\u001B[0m     \u001B[38;5;66;03m# a ProxyError.\u001B[39;00m\n\u001B[0;32m    725\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m exc\u001B[38;5;241m.\u001B[39m_request \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:152\u001B[0m, in \u001B[0;36mSyncConnectionPool.request\u001B[1;34m(self, method, url, headers, stream, timeout)\u001B[0m\n\u001B[0;32m    149\u001B[0m         logger\u001B[38;5;241m.\u001B[39mtrace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreuse connection=\u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, connection)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 152\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    153\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m NewConnectionRequired:\n\u001B[0;32m    156\u001B[0m     connection \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\httpcore\\_sync\\connection.py:65\u001B[0m, in \u001B[0;36mSyncHTTPConnection.request\u001B[1;34m(self, method, url, headers, stream, timeout)\u001B[0m\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msocket:\n\u001B[0;32m     62\u001B[0m         logger\u001B[38;5;241m.\u001B[39mtrace(\n\u001B[0;32m     63\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mopen_socket origin=\u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m timeout=\u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39morigin, timeout\n\u001B[0;32m     64\u001B[0m         )\n\u001B[1;32m---> 65\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msocket \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open_socket\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_connection(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msocket)\n\u001B[0;32m     67\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;129;01min\u001B[39;00m (ConnectionState\u001B[38;5;241m.\u001B[39mREADY, ConnectionState\u001B[38;5;241m.\u001B[39mIDLE):\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\httpcore\\_sync\\connection.py:85\u001B[0m, in \u001B[0;36mSyncHTTPConnection._open_socket\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m     83\u001B[0m ssl_context \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mssl_context \u001B[38;5;28;01mif\u001B[39;00m scheme \u001B[38;5;241m==\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 85\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen_tcp_stream\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     86\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhostname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mport\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mssl_context\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\n\u001B[0;32m     87\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     88\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m     89\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconnect_failed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\httpcore\\_backends\\sync.py:139\u001B[0m, in \u001B[0;36mSyncBackend.open_tcp_stream\u001B[1;34m(self, hostname, port, ssl_context, timeout)\u001B[0m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ssl_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    136\u001B[0m     sock \u001B[38;5;241m=\u001B[39m ssl_context\u001B[38;5;241m.\u001B[39mwrap_socket(\n\u001B[0;32m    137\u001B[0m         sock, server_hostname\u001B[38;5;241m=\u001B[39mhostname\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mascii\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    138\u001B[0m     )\n\u001B[1;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m SyncSocketStream(sock\u001B[38;5;241m=\u001B[39msock)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\contextlib.py:131\u001B[0m, in \u001B[0;36m_GeneratorContextManager.__exit__\u001B[1;34m(self, type, value, traceback)\u001B[0m\n\u001B[0;32m    129\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m()\n\u001B[0;32m    130\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 131\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mthrow\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraceback\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    132\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m    133\u001B[0m     \u001B[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001B[39;00m\n\u001B[0;32m    134\u001B[0m     \u001B[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001B[39;00m\n\u001B[0;32m    135\u001B[0m     \u001B[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001B[39;00m\n\u001B[0;32m    136\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m exc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m value\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\httpcore\\_exceptions.py:12\u001B[0m, in \u001B[0;36mmap_exceptions\u001B[1;34m(map)\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m from_exc, to_exc \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mmap\u001B[39m\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(exc, from_exc):\n\u001B[1;32m---> 12\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m to_exc(exc) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[1;31mConnectTimeout\u001B[0m: timed out"
     ]
    }
   ],
   "source": [
    "simple_translator(\"de\", \"predefined_dictionary\", \"stanford_OpenIE\") # CAUTION: since this uses API it can \"timeout\", so if happens just run it again"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T15:28:08.805818800Z",
     "start_time": "2023-05-18T15:23:28.134284300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\dnaen\\\\PycharmProjects\\\\bachelor_thesis_23\\\\data\\\\en\\\\directives_txt_tagged'"
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T17:34:09.929907200Z",
     "start_time": "2023-05-18T17:34:09.866078800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trash"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "# nltk.download('punkt') # unsupervised trainable model, which means it can be trained on unlabeled data (Data that has not been tagged with information identifying its characteristics, properties, or categories is referred to as unlabeled data.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "# the code below can be used to check what were the new concepts that were added\n",
    "temp = list(updated_concept_list.values())\n",
    "my_dict = {i: temp.count(i) for i in temp}\n",
    "multiple_elements = []\n",
    "for key, value in my_dict.items():\n",
    "    if value > 1:\n",
    "        multiple_elements.append(key)\n",
    "\n",
    "for elem in multiple_elements:\n",
    "    value = {i for i in updated_concept_list if updated_concept_list[i] == elem}\n",
    "    print(str(value) + \" in id: \" + elem)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:13:23.657289Z",
     "start_time": "2023-05-09T17:13:23.645204Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
